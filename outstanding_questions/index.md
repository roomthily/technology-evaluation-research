---
layout: page
---

### Outstanding Questions ###

1. What categories are missing from this evaluation process?
2. Which of the TRL criteria are no longer necessary (if any)? 
3. What criteria are missing from the existing categories?
4. What categories are superfluous (if any)?
5. What is the difference from good code practices and this idea of readiness level?
6. What do we consider just basic code practices for a baseline given 5?
7. What types of software can be evaluated within this kind of framework?
8. How do the criteria vary across those software types?
9. But, even in that variation, can a set of core categories and criteria be identified?
10. How can "maintenance-only" or "unmaintained" be captured in readiness levels or in an evaluation category?
11. Are there criteria for research software objects specifically that should be included in any evaluation process?
12. How can these kinds core criteria be used to develop scaffolds for education purposes?
13. Is there a minimum viable evaluation product?
14. If we can create a progression beyond simply good code practices, can it be structured in a way that is meaningful from an implementation perspective?