---
layout: guidelines
---

# Software Assessment Guidelines #

**In Draft 5/15/2016**

## Abstract ##


## Goals of this Document ##


- To provide a basis for assessment guidelines that are effective and actionable both during active development and maintenance phases of research projects.
- To provide assessment guidelines to support different research group stages [ALSO NOT GREAT].
- To provide assessment guidelines effective for a range of stakeholders, from funders to individual researchers.
- To develop guidelines structured to reflect good code practices [THIS PHRASE IS NOT GREAT] and incorporating features related to research code requirements.


## HEADER TO COME ##


### Use Cases ###


Stakeholder | Use Case
----------- | --------
Funder | As a funding agency, we're interested in evaluating the software projects we fund.  
Project Manager, Principal Investigator (manager in practice) | As a manager, I’m interested in using the rubric/progression as a learning tool to help improve the development practices in my research group.
Principal Investigator | As a PI, I would like a tool to assess our progress and ensure we’re meeting our funder’s expectations for a software project based on the readiness level stated in the original proposal and as defined by the funder.
Science Software Developer, Researcher Who Codes | As a science software developer, I’m interested in using the recommended practices to improve my own workflow and skillsets.
Developer | As a developer, I would like community-supported guidelines to support requests to change our current dev team practices.
Grad Student, Post-Doc, Researcher interested in continuing code education | I’ve taken the introductory courses and want to continue to improve my skills but don’t know good next steps. I’d like guidance on next steps given my skillset.
Research Community | We want to provide educational materials or other support for community members to meet their goals re: research software implementation and career growth.

### What Are We Assessing ###


### Limitations of these Guidelines ###



[Examples of practices that are recommended but leave little to no trace for assessment.]



## Guidelines ##

[Reference and note for the descriptions of the bins and which ones are added for this doc.]

These guidelines are based on the criteria developed by the Software Sustainability Institute [REF], [other info], and feedback based on several ESIP activities. 

[Brief description of the development of these guidelines through ESIP, EarthCube, LASP, BESSIG]

The guidelines described in this document are, in large part, based on previous work by the Software Sustainability Institute and the Technology Assessment Framework (J. Greybeal as an ESIP Testbed grant). 


- revisions for currentness and to reflect ESIP's goals related to education and mentorship
- revisions for composability: for encouraging change over time (replace smaller component with newer definitions) and to more explicitly define criteria for understandability and educational purposes. & for defining progressions.
- revisions for assessment metrics: clarify the application of the guidelines for the identified areas (project types, project or codebase, etc) for ease of use during the assessment process.


[Define the ESIP Core requirements]

[Define the binning, etc]

[Describe the design.]

{% include guidelines.html %}


## Participants ##


## References ##




